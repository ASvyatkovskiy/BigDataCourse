{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Spark SQL\n",
    "\n",
    "Spark SQL allows one to query structured data in Spark applications. It supports 2 query parsers: SQL and HiveQL.\n",
    "We will focus on SQL in the following. Spark SQL and dataframes are often used as synonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Spark DataFrames with Python\n",
    "This notebook demonstrates a number of common Spark DataFrames functions using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id='123456', name='Computer Science')\n",
      "Row(firstName='xiangrui', lastName='meng', email='no-reply@stanford.edu', salary=120000)\n",
      "no-reply@berkeley.edu\n"
     ]
    }
   ],
   "source": [
    "# import pyspark class Row from module sql\n",
    "from pyspark.sql import *\n",
    "# Create Example Data - Departments and Employees\n",
    "\n",
    "# Create the Departments\n",
    "department1 = Row(id='123456', name='Computer Science')\n",
    "department2 = Row(id='789012', name='Mechanical Engineering')\n",
    "department3 = Row(id='345678', name='Theater and Drama')\n",
    "department4 = Row(id='901234', name='Indoor Recreation')\n",
    "\n",
    "# Create the Employees\n",
    "Employee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\n",
    "employee1 = Employee('michael', 'armbrust', 'no-reply@berkeley.edu', 100000)\n",
    "employee2 = Employee('xiangrui', 'meng', 'no-reply@stanford.edu', 120000)\n",
    "employee3 = Employee('matei', None, 'no-reply@waterloo.edu', 140000)\n",
    "employee4 = Employee(None, 'wendell', 'no-reply@berkeley.edu', 160000)\n",
    "\n",
    "# Create the DepartmentWithEmployees instances from Departments and Employees\n",
    "departmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2])\n",
    "departmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4])\n",
    "departmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4])\n",
    "departmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])\n",
    "\n",
    "print department1\n",
    "print employee2\n",
    "print departmentWithEmployees1.employees[0].email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create the first DataFrame from a list of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          department|           employees|\n",
      "+--------------------+--------------------+\n",
      "|[123456,Computer ...|[[michael,armbrus...|\n",
      "|[789012,Mechanica...|[[matei,null,no-r...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departmentsWithEmployeesSeq1 = [departmentWithEmployees1, departmentWithEmployees2]\n",
    "df1 = spark.createDataFrame(departmentsWithEmployeesSeq1)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a 2nd DataFrame from a list of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          department|           employees|\n",
      "+--------------------+--------------------+\n",
      "|[345678,Theater a...|[[michael,armbrus...|\n",
      "|[901234,Indoor Re...|[[xiangrui,meng,n...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departmentsWithEmployeesSeq2 = [departmentWithEmployees3, departmentWithEmployees4]\n",
    "df2 = spark.createDataFrame(departmentsWithEmployeesSeq2)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Working with DataFrames\n",
    "\n",
    "Union to DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          department|           employees|\n",
      "+--------------------+--------------------+\n",
      "|[123456,Computer ...|[[michael,armbrus...|\n",
      "|[789012,Mechanica...|[[matei,null,no-r...|\n",
      "|[345678,Theater a...|[[michael,armbrus...|\n",
      "|[901234,Indoor Re...|[[xiangrui,meng,n...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unionDF = df1.unionAll(df2)\n",
    "unionDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write the Unioned DataFrame to a Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# we will define this utility function once again inline here\n",
    "def output_cleaner():\n",
    "    import os\n",
    "    os.system(\"rm -rf ./output*\")\n",
    "    print \"Output folders removed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folders removed!\n"
     ]
    }
   ],
   "source": [
    "#clean tmp directories if necessary\n",
    "output_cleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unionDF.write.parquet(\"./output_parquet/dfexample_parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Read a DataFrame from the Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          department|           employees|\n",
      "+--------------------+--------------------+\n",
      "|[345678,Theater a...|[[michael,armbrus...|\n",
      "|[123456,Computer ...|[[michael,armbrus...|\n",
      "|[789012,Mechanica...|[[matei,null,no-r...|\n",
      "|[901234,Indoor Re...|[[xiangrui,meng,n...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquetDF = spark.read.parquet(\"./output_parquet/dfexample_parquet\")\n",
    "parquetDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Explode Function:\n",
    "\n",
    "Explode the employees column.\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/functions.html#explode\n",
    "\n",
    "```python\n",
    "def explode(col):\n",
    "    \"\"\"Returns a new row for each element in the given array or map.\n",
    "\n",
    "    >>> from pyspark.sql import Row\n",
    "    >>> eDF = spark.createDataFrame([Row(a=1, intlist=[1,2,3], mapfield={\"a\": \"b\"})])\n",
    "    >>> eDF.select(explode(eDF.intlist).alias(\"anInt\")).collect()\n",
    "    [Row(anInt=1), Row(anInt=2), Row(anInt=3)]\n",
    "\n",
    "    >>> eDF.select(explode(eDF.mapfield).alias(\"key\", \"value\")).show()\n",
    "    +---+-----+\n",
    "    |key|value|\n",
    "    +---+-----+\n",
    "    |  a|    b|\n",
    "    +---+-----+\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "|     null| wendell|no-reply@berkeley...|160000|\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "|    matei|    null|no-reply@waterloo...|140000|\n",
      "|     null| wendell|no-reply@berkeley...|160000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "|    matei|    null|no-reply@waterloo...|140000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df = parquetDF.select(explode(\"employees\").alias(\"e\"))\n",
    "explodeDF = df.selectExpr(\"e.firstName\", \"e.lastName\", \"e.email\", \"e.salary\")\n",
    "explodeDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[firstName: string, lastName: string, email: string, salary: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explodeDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filterDF = explodeDF.filter(explodeDF.firstName == \"xiangrui\").sort(explodeDF.lastName)\n",
    "filterDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, asc\n",
    "\n",
    "# Use `|` instead of `or` \n",
    "filterDF = explodeDF.filter((col(\"firstName\") == \"xiangrui\") | (col(\"firstName\") == \"michael\")).sort(asc(\"lastName\"))\n",
    "filterDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The where() clause is equivalent to filter()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "whereDF = explodeDF.where((col(\"firstName\") == \"xiangrui\") | (col(\"firstName\") == \"michael\")).sort(asc(\"lastName\"))\n",
    "whereDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Replace null values with -- using DataFrame Na functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "|       --| wendell|no-reply@berkeley...|160000|\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "|    matei|      --|no-reply@waterloo...|140000|\n",
      "|       --| wendell|no-reply@berkeley...|160000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "|    matei|      --|no-reply@waterloo...|140000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nonNullDF = explodeDF.fillna(\"--\")\n",
    "nonNullDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Retrieve only rows with missing firstName or lastName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|     null| wendell|no-reply@berkeley...|160000|\n",
      "|     null| wendell|no-reply@berkeley...|160000|\n",
      "|    matei|    null|no-reply@waterloo...|140000|\n",
      "|    matei|    null|no-reply@waterloo...|140000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filterNonNullDF = explodeDF.filter(col(\"firstName\").isNull() | col(\"lastName\").isNull()).sort(\"email\")\n",
    "filterNonNullDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Example aggregations using agg() and countDistinct()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------------------------+\n",
      "|firstName|lastName|count(DISTINCT firstName)|\n",
      "+---------+--------+-------------------------+\n",
      "|     null| wendell|                        0|\n",
      "|    matei|    null|                        1|\n",
      "| xiangrui|    meng|                        1|\n",
      "|  michael|armbrust|                        1|\n",
      "+---------+--------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "countDistinctDF = explodeDF.select(\"firstName\", \"lastName\")\\\n",
    "  .groupBy(\"firstName\", \"lastName\").agg(countDistinct(\"firstName\"))\n",
    "\n",
    "countDistinctDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compare the DataFrame and SQL Query Physical Plans (Hint: They should be the same.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*HashAggregate(keys=[firstName#60, lastName#61], functions=[count(distinct firstName#60)])\n",
      "+- *HashAggregate(keys=[firstName#60, lastName#61], functions=[partial_count(distinct firstName#60)])\n",
      "   +- *HashAggregate(keys=[firstName#60, lastName#61, firstName#60], functions=[])\n",
      "      +- Exchange hashpartitioning(firstName#60, lastName#61, firstName#60, 200)\n",
      "         +- *HashAggregate(keys=[firstName#60, lastName#61, firstName#60], functions=[])\n",
      "            +- *Project [e#57.firstName AS firstName#60, e#57.lastName AS lastName#61]\n",
      "               +- Generate explode(employees#32), false, false, [e#57]\n",
      "                  +- *FileScan parquet [employees#32] Batched: false, Format: Parquet, Location: InMemoryFileIndex[file:/Users/alexey/Desktop/BigDataCourse/3_DataFramesSQL/output_parquet/dfexamp..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<employees:array<struct<firstName:string,lastName:string,email:string,salary:bigint>>>\n"
     ]
    }
   ],
   "source": [
    "countDistinctDF.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*HashAggregate(keys=[firstName#60, lastName#61], functions=[count(distinct firstName#60)])\n",
      "+- *HashAggregate(keys=[firstName#60, lastName#61], functions=[partial_count(distinct firstName#60)])\n",
      "   +- *HashAggregate(keys=[firstName#60, lastName#61, firstName#60], functions=[])\n",
      "      +- Exchange hashpartitioning(firstName#60, lastName#61, firstName#60, 200)\n",
      "         +- *HashAggregate(keys=[firstName#60, lastName#61, firstName#60], functions=[])\n",
      "            +- *Project [e#57.firstName AS firstName#60, e#57.lastName AS lastName#61]\n",
      "               +- Generate explode(employees#32), false, false, [e#57]\n",
      "                  +- *FileScan parquet [employees#32] Batched: false, Format: Parquet, Location: InMemoryFileIndex[file:/Users/alexey/Desktop/BigDataCourse/3_DataFramesSQL/output_parquet/dfexamp..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<employees:array<struct<firstName:string,lastName:string,email:string,salary:bigint>>>\n"
     ]
    }
   ],
   "source": [
    "# register the DataFrame as a temp table so that we can query it using SQL\n",
    "explodeDF.registerTempTable(\"df_example\")\n",
    "\n",
    "# Perform the same query as the DataFrame above and return ``explain``\n",
    "countDistinctDF_sql = spark.sql(\"SELECT firstName, lastName, count(distinct firstName) as distinct_first_names FROM df_example GROUP BY firstName, lastName\")\n",
    "\n",
    "countDistinctDF_sql.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sum up all the salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|    1040000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salarySumDF = explodeDF.agg({\"salary\" : \"sum\"}) \n",
    "salarySumDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(explodeDF.salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Print the summary statistics for the salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            salary|\n",
      "+-------+------------------+\n",
      "|  count|                 8|\n",
      "|   mean|          130000.0|\n",
      "| stddev|23904.572186687874|\n",
      "|    min|            100000|\n",
      "|    max|            160000|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explodeDF.describe(\"salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### An example using Pandas & Matplotlib Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1124ff190>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1125c8750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEkCAYAAADTtG33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhpmZFfb/ASqPqSfDI7i7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1125c8f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "plt.clf()\n",
    "pdDF = nonNullDF.toPandas()\n",
    "pdDF.plot(x='firstName', y='salary', kind='bar', rot=45)\n",
    "#display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## User Defined Functions in Python\n",
    "\n",
    "This notebook contains an examples of creating a UDF in Python and registering it for use in Spark SQL.\n",
    "\n",
    "\n",
    "#### Step 1: Register a function as a UDF.\n",
    "\n",
    "After the standard function is defined in Python, you need to register it as a UDF to be able to use on Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def squared(s):\n",
    "    return s * s\n",
    "\n",
    "spark.udf.register(\"squaredWithPython\", squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Optionally, you can also explicitly set the return type of your UDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType\n",
    "def squared_typed(s):\n",
    "    return s * s\n",
    "\n",
    "sqlContext.udf.register(\"squaredWithPython\", squared, LongType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Step 2: Call the UDF in Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sqlContext.range(1, 20).registerTempTable(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Step 3: Use UDF with DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|id_squared|\n",
      "+---+----------+\n",
      "|  1|         1|\n",
      "|  2|         4|\n",
      "|  3|         9|\n",
      "|  4|        16|\n",
      "|  5|        25|\n",
      "|  6|        36|\n",
      "|  7|        49|\n",
      "|  8|        64|\n",
      "|  9|        81|\n",
      "| 10|       100|\n",
      "| 11|       121|\n",
      "| 12|       144|\n",
      "| 13|       169|\n",
      "| 14|       196|\n",
      "| 15|       225|\n",
      "| 16|       256|\n",
      "| 17|       289|\n",
      "| 18|       324|\n",
      "| 19|       361|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "squared_udf = udf(squared, LongType())\n",
    "df = spark.table(\"test\")\n",
    "df.select(\"id\", squared_udf(\"id\").alias(\"id_squared\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

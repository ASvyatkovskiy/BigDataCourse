{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is Python's answer to R.  It's a good tool for small(ish) data analysis -- i.e., when everything fits into memory.\n",
    "\n",
    "The basic new \"noun\" in pandas is the **data frame**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a data frame\n",
    "\n",
    "It's like a table, with rows and columns (e.g., as in SQL).  Except:\n",
    "  - The rows can be indexed by something interesting (there is special support for labels like categorical and timeseries data).  This is especially useful when you have timeseries data with potentially missing data points.\n",
    "  - Cells can store Python objects. (Like in SQL, columns are homogeneous.)\n",
    "  - Instead of \"NULL\", the name for a non-existent value is \"NA\".  Unlike R, Python's data frames only support NAs in columns of some data types (basically: floating point numbers and 'objects') -- but this is mostly a non-issue (because it will \"up-cast\" integers to float64, etc.)\n",
    "  \n",
    "Pandas provides a \"batteries-included\" basic data analysis:\n",
    "  - **Loading data:** `read_csv`, `read_table`, `read_sql`, and `read_html`\n",
    "  - **Selection, filtering, and aggregation** (i.e., SQL-type operations): There's a special syntax for `SELECT`ing.  There's the `merge` method for `JOIN`ing.  There's also an easy syntax for what in SQL is a mouthful: Creating a new column whose value is computed from other column -- with the bonus that now the computations can use the full power of Python (though it might be faster if it didn't).\n",
    "  - **\"Pivot table\" style aggregation**: If you're an Excel cognosceti, you may appreciate this.\n",
    "  - **NA handling**: Like R's data frames, there is good support for transforming NA values with default values / averaging tricks / etc.\n",
    "  - **Basic statistics:** e.g. `mean`, `median`, `max`, `min`, and the convenient `describe`.\n",
    "  - **Plugging into more advanced analytics:** Okay, this isn't batteries included.  But still, it plays reasonably with `sklearn`.\n",
    "  - **Visualization:** For instance `plot` and `hist`.\n",
    "  \n",
    "We'll go through a little on all of these in the context of an example.  To go through it, you must have the (output) data files from the HMDA \"Project structure\" example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to explore a dataset of mortgage insurance issued by the Federal Housing Authority (FHA).  The data is broken down by census tract and tells us how big of a player the FHA is in each tract (how many homes etc ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data (and basic statistics / visualization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Census_Tract_Number</th>\n",
       "      <th>NUM_ALL</th>\n",
       "      <th>NUM_FHA</th>\n",
       "      <th>PCT_NUM_FHA</th>\n",
       "      <th>AMT_ALL</th>\n",
       "      <th>AMT_FHA</th>\n",
       "      <th>PCT_AMT_FHA</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9613.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>2184</td>\n",
       "      <td>799</td>\n",
       "      <td>36.58420</td>\n",
       "      <td>1.049961e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55215</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5000</td>\n",
       "      <td>774</td>\n",
       "      <td>76</td>\n",
       "      <td>9.81912</td>\n",
       "      <td>1.003010e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>1495</td>\n",
       "      <td>263</td>\n",
       "      <td>17.59200</td>\n",
       "      <td>1.095031e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33750</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9618.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>21.4286</td>\n",
       "      <td>1243</td>\n",
       "      <td>333</td>\n",
       "      <td>26.79000</td>\n",
       "      <td>1.039962e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Code  County_Code  Census_Tract_Number  NUM_ALL  NUM_FHA  \\\n",
       "23999         1.0         49.0               9613.0       16        4   \n",
       "55215         1.0          3.0                102.0        8        1   \n",
       "65492         1.0         27.0                  NaN        1        0   \n",
       "45193         1.0         95.0                311.0       20        3   \n",
       "33750         1.0         39.0               9618.0       14        3   \n",
       "\n",
       "       PCT_NUM_FHA  AMT_ALL  AMT_FHA  PCT_AMT_FHA         GEOID  \n",
       "23999      25.0000     2184      799     36.58420  1.049961e+09  \n",
       "55215      12.5000      774       76      9.81912  1.003010e+09  \n",
       "65492       0.0000       82        0      0.00000           NaN  \n",
       "45193      15.0000     1495      263     17.59200  1.095031e+09  \n",
       "33750      21.4286     1243      333     26.79000  1.039962e+09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names =[\"State_Code\", \"County_Code\", \"Census_Tract_Number\", \"NUM_ALL\", \"NUM_FHA\", \"PCT_NUM_FHA\", \"AMT_ALL\", \"AMT_FHA\", \"PCT_AMT_FHA\"]\n",
    "df = pd.read_csv('./data/fha_by_tract.csv', names=names)  ## Loading a CSV file, without a header (so we have to provide field names)\n",
    "\n",
    "df['GEOID'] = df['Census_Tract_Number']*100 + 10**6 * df['County_Code'] \\\n",
    "    + 10**9 * df['State_Code']   ## A computed field!\n",
    "    \n",
    "df = df.sort_values('State_Code')  # sorting data to make it easier to read\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    72035.000000\n",
      "mean        29.703179\n",
      "std         24.037779\n",
      "min          0.000000\n",
      "25%         10.780800\n",
      "50%         24.753900\n",
      "75%         44.207550\n",
      "max        100.000000\n",
      "Name: PCT_AMT_FHA, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6bd76a78d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic statistics and a histogram of the percentage of mortages \n",
    "# in each census tract insured by FHA\n",
    "print( df['PCT_AMT_FHA'].describe() )\n",
    "df['PCT_AMT_FHA'].hist(bins=50, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    72035.000000\n",
      "mean         8.169060\n",
      "std          1.431749\n",
      "min          0.693147\n",
      "25%          7.346655\n",
      "50%          8.335192\n",
      "75%          9.176577\n",
      "max         14.270319\n",
      "Name: LOG_AMT_ALL, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6bd76a78d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above distribution looks a little skewed, let's look at it's log\n",
    "\n",
    "# We can save off the data into a new column\n",
    "df['LOG_AMT_ALL'] = np.log(df['AMT_ALL'])\n",
    "print (df['LOG_AMT_ALL'].describe())\n",
    "\n",
    "# We can use the apply function to transform data\n",
    "df['AMT_ALL'].apply(np.log).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23999    1.0\n",
      "55215    1.0\n",
      "65492    1.0\n",
      "45193    1.0\n",
      "33750    1.0\n",
      "Name: State_Code, dtype: float64\n",
      "       State_Code  County_Code\n",
      "23999         1.0         49.0\n",
      "55215         1.0          3.0\n",
      "65492         1.0         27.0\n",
      "45193         1.0         95.0\n",
      "33750         1.0         39.0\n",
      "['State_Code', 'County_Code', 'Census_Tract_Number', 'NUM_ALL', 'NUM_FHA', 'PCT_NUM_FHA', 'AMT_ALL', 'AMT_FHA', 'PCT_AMT_FHA', 'GEOID', 'LOG_AMT_ALL']\n"
     ]
    }
   ],
   "source": [
    "# Selecting off a column\n",
    "print (df['State_Code'].head())\n",
    "\n",
    "# Selecting off multiple columns\n",
    "print (df[['State_Code', 'County_Code']].head())\n",
    "\n",
    "# programatically access column names\n",
    "print ([col for col in df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "This is a slightly fancied up version of Python's index notation.  When you write something like \n",
    "\n",
    "        df['column_name']==5\n",
    "\n",
    "what's actually happening is that pandas creates a new, __binary__, data series indexed by the same indexing set as `df`.  You can combine such binary series using the term-wise `&` (`and`) and term-wise `|` (`or`) operations.  For instance:\n",
    "\n",
    "        df['column_name2']==MD & ( df['column_name1']==5 | df['column_name2']==6 )\n",
    "\n",
    "Now the `df[...]` notation is very flexible:\n",
    "  - It accepts column names;\n",
    "  - It accepts column numbers (so long as there is no ambiguity with column names..);\n",
    "  - It accepsts _binary data series!_\n",
    "  \n",
    "This means that you can write\n",
    "\n",
    "        df[ df['column_name2']==MD & ( df['column_name1']==5 | df['column_name1']==6 ) ]\n",
    "   \n",
    "for what you would write in SQL as\n",
    "\n",
    ">         SELECT * FROM df WHERE\n",
    "            column_name2='MD\" AND (column_name1=5 OR column_name1=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23999    True\n",
      "55215    True\n",
      "65492    True\n",
      "45193    True\n",
      "33750    True\n",
      "Name: State_Code, dtype: bool\n",
      "23999     True\n",
      "55215    False\n",
      "65492    False\n",
      "45193    False\n",
      "33750    False\n",
      "dtype: bool\n",
      "23999     True\n",
      "55215    False\n",
      "65492    False\n",
      "45193    False\n",
      "33750    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Selection returns a boolean array ..\n",
    "print ((df['State_Code'] == 1).head())\n",
    "\n",
    "# ... we can apply the usual boolean operators to it\n",
    "print (((df['State_Code'] == 1) & (df['Census_Tract_Number'] == 9613)).head())\n",
    "\n",
    "# pandas indices take boolean lists of the appropriate length\n",
    "print (((df['State_Code'] == 1) & (df['Census_Tract_Number'] == 9613)).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join-ing\n",
    "\n",
    "The analogue of a\n",
    "\n",
    ">             \n",
    "    SELECT * \n",
    "        FROM df1\n",
    "        INNER JOIN df2 \n",
    "        ON df1.field_name=df2.field_name;\n",
    "\n",
    "is\n",
    "\n",
    "    df_joined = df1.merge(df2, on='field_name')\n",
    "\n",
    "You can also do left / right / outer joins, mix-and-match column names, etc.  For that consult the Pandas documentation. (The example below will do a left join..)\n",
    "\n",
    "Of course, just looking at the distribution of insurance by census tract isn't interesting unless we know more about the census tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Census_Tract_Number</th>\n",
       "      <th>NUM_ALL</th>\n",
       "      <th>NUM_FHA</th>\n",
       "      <th>PCT_NUM_FHA</th>\n",
       "      <th>AMT_ALL</th>\n",
       "      <th>AMT_FHA</th>\n",
       "      <th>PCT_AMT_FHA</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>LOG_AMT_ALL</th>\n",
       "      <th>USPS</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>ALAND_SQMI</th>\n",
       "      <th>AWATER_SQMI</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72034</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9477</td>\n",
       "      <td>1932</td>\n",
       "      <td>20.38620</td>\n",
       "      <td>1575871</td>\n",
       "      <td>331515</td>\n",
       "      <td>21.036900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.270319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64830</th>\n",
       "      <td>48.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>6731.01</td>\n",
       "      <td>2329</td>\n",
       "      <td>363</td>\n",
       "      <td>15.58610</td>\n",
       "      <td>578838</td>\n",
       "      <td>76312</td>\n",
       "      <td>13.183700</td>\n",
       "      <td>4.815767e+10</td>\n",
       "      <td>13.268778</td>\n",
       "      <td>TX</td>\n",
       "      <td>50922560.0</td>\n",
       "      <td>384718.0</td>\n",
       "      <td>19.661</td>\n",
       "      <td>0.149</td>\n",
       "      <td>29.744280</td>\n",
       "      <td>-95.815507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>170.30</td>\n",
       "      <td>574</td>\n",
       "      <td>58</td>\n",
       "      <td>10.10450</td>\n",
       "      <td>284965</td>\n",
       "      <td>31840</td>\n",
       "      <td>11.173300</td>\n",
       "      <td>6.073017e+09</td>\n",
       "      <td>12.560122</td>\n",
       "      <td>CA</td>\n",
       "      <td>33370884.0</td>\n",
       "      <td>1297044.0</td>\n",
       "      <td>12.885</td>\n",
       "      <td>0.501</td>\n",
       "      <td>33.036238</td>\n",
       "      <td>-117.126757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8857</th>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>615.00</td>\n",
       "      <td>357</td>\n",
       "      <td>4</td>\n",
       "      <td>1.12045</td>\n",
       "      <td>271648</td>\n",
       "      <td>2165</td>\n",
       "      <td>0.796987</td>\n",
       "      <td>6.075062e+09</td>\n",
       "      <td>12.512262</td>\n",
       "      <td>CA</td>\n",
       "      <td>1669698.0</td>\n",
       "      <td>439050.0</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.170</td>\n",
       "      <td>37.787726</td>\n",
       "      <td>-122.392389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8890</th>\n",
       "      <td>6.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>626.43</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>1.53846</td>\n",
       "      <td>223532</td>\n",
       "      <td>1484</td>\n",
       "      <td>0.663887</td>\n",
       "      <td>6.059063e+09</td>\n",
       "      <td>12.317310</td>\n",
       "      <td>CA</td>\n",
       "      <td>18821408.0</td>\n",
       "      <td>1549909.0</td>\n",
       "      <td>7.267</td>\n",
       "      <td>0.598</td>\n",
       "      <td>33.595088</td>\n",
       "      <td>-117.829038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Code  County_Code  Census_Tract_Number  NUM_ALL  NUM_FHA  \\\n",
       "72034         NaN          NaN                  NaN     9477     1932   \n",
       "64830        48.0        157.0              6731.01     2329      363   \n",
       "7795          6.0         73.0               170.30      574       58   \n",
       "8857          6.0         75.0               615.00      357        4   \n",
       "8890          6.0         59.0               626.43      130        2   \n",
       "\n",
       "       PCT_NUM_FHA  AMT_ALL  AMT_FHA  PCT_AMT_FHA         GEOID  LOG_AMT_ALL  \\\n",
       "72034     20.38620  1575871   331515    21.036900           NaN    14.270319   \n",
       "64830     15.58610   578838    76312    13.183700  4.815767e+10    13.268778   \n",
       "7795      10.10450   284965    31840    11.173300  6.073017e+09    12.560122   \n",
       "8857       1.12045   271648     2165     0.796987  6.075062e+09    12.512262   \n",
       "8890       1.53846   223532     1484     0.663887  6.059063e+09    12.317310   \n",
       "\n",
       "      USPS       ALAND     AWATER  ALAND_SQMI  AWATER_SQMI   INTPTLAT  \\\n",
       "72034  NaN         NaN        NaN         NaN          NaN        NaN   \n",
       "64830   TX  50922560.0   384718.0      19.661        0.149  29.744280   \n",
       "7795    CA  33370884.0  1297044.0      12.885        0.501  33.036238   \n",
       "8857    CA   1669698.0   439050.0       0.645        0.170  37.787726   \n",
       "8890    CA  18821408.0  1549909.0       7.267        0.598  33.595088   \n",
       "\n",
       "       INTPTLONG                                                                                                                               \n",
       "72034                                                NaN                                                                                       \n",
       "64830                                         -95.815507                                                                                       \n",
       "7795                                         -117.126757                                                                                       \n",
       "8857                                         -122.392389                                                                                       \n",
       "8890                                         -117.829038                                                                                       "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading information about census tracts\n",
    "df_geo = pd.read_csv('./data/2013_Gaz_tracts_national.tsv', sep='\\t')\n",
    "\n",
    "# And join it in\n",
    "df_joined = df.merge(df_geo, on='GEOID', how='left')\n",
    "df_joined.sort_values('AMT_ALL', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "The analog of SQL's `GROUP BY` is\n",
    "\n",
    "    grouped = df.groupby(['field_name1', ...])\n",
    "\n",
    "The above is analogous to\n",
    ">             \n",
    "    SELECT * \n",
    "        FROM df\n",
    "        GROUP BY df.field_name1, ...\n",
    "\n",
    "Pandas is somewhat more flexible in how you can use grouping, not requiring you to specify an aggregation function up front.  A few examples are:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Census_Tract_Number</th>\n",
       "      <th>NUM_ALL</th>\n",
       "      <th>NUM_FHA</th>\n",
       "      <th>PCT_NUM_FHA</th>\n",
       "      <th>AMT_ALL</th>\n",
       "      <th>AMT_FHA</th>\n",
       "      <th>PCT_AMT_FHA</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>LOG_AMT_ALL</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>ALAND_SQMI</th>\n",
       "      <th>AWATER_SQMI</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLONG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>3797</td>\n",
       "      <td>644</td>\n",
       "      <td>16.9608</td>\n",
       "      <td>2.122001e+09</td>\n",
       "      <td>8.241967</td>\n",
       "      <td>120428818.0</td>\n",
       "      <td>13605012.0</td>\n",
       "      <td>46.498</td>\n",
       "      <td>5.253</td>\n",
       "      <td>59.708319</td>\n",
       "      <td>-151.545304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9613.00</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>2184</td>\n",
       "      <td>799</td>\n",
       "      <td>36.5842</td>\n",
       "      <td>1.049961e+09</td>\n",
       "      <td>7.688913</td>\n",
       "      <td>91371430.0</td>\n",
       "      <td>86324.0</td>\n",
       "      <td>35.279</td>\n",
       "      <td>0.033</td>\n",
       "      <td>34.457495</td>\n",
       "      <td>-85.635214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9702.00</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>28.5714</td>\n",
       "      <td>1645</td>\n",
       "      <td>535</td>\n",
       "      <td>32.5228</td>\n",
       "      <td>5.025970e+09</td>\n",
       "      <td>7.405496</td>\n",
       "      <td>812912293.0</td>\n",
       "      <td>1721231.0</td>\n",
       "      <td>313.867</td>\n",
       "      <td>0.665</td>\n",
       "      <td>33.814492</td>\n",
       "      <td>-92.147621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>41.15</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>64.7059</td>\n",
       "      <td>3284</td>\n",
       "      <td>2264</td>\n",
       "      <td>68.9403</td>\n",
       "      <td>4.019004e+09</td>\n",
       "      <td>8.096817</td>\n",
       "      <td>3168111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.223</td>\n",
       "      <td>0.000</td>\n",
       "      <td>32.143460</td>\n",
       "      <td>-110.918635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4029.04</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>46.8750</td>\n",
       "      <td>4976</td>\n",
       "      <td>3229</td>\n",
       "      <td>64.8915</td>\n",
       "      <td>6.037403e+09</td>\n",
       "      <td>8.512382</td>\n",
       "      <td>1903988.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>34.026072</td>\n",
       "      <td>-117.736203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_Code  County_Code  Census_Tract_Number  NUM_ALL  NUM_FHA  \\\n",
       "USPS                                                                   \n",
       "AK           2.0        122.0                 9.00       15        3   \n",
       "AL           1.0         49.0              9613.00       16        4   \n",
       "AR           5.0         25.0              9702.00       14        4   \n",
       "AZ           4.0         19.0                41.15       34       22   \n",
       "CA           6.0         37.0              4029.04       32       15   \n",
       "\n",
       "      PCT_NUM_FHA  AMT_ALL  AMT_FHA  PCT_AMT_FHA         GEOID  LOG_AMT_ALL  \\\n",
       "USPS                                                                          \n",
       "AK        20.0000     3797      644      16.9608  2.122001e+09     8.241967   \n",
       "AL        25.0000     2184      799      36.5842  1.049961e+09     7.688913   \n",
       "AR        28.5714     1645      535      32.5228  5.025970e+09     7.405496   \n",
       "AZ        64.7059     3284     2264      68.9403  4.019004e+09     8.096817   \n",
       "CA        46.8750     4976     3229      64.8915  6.037403e+09     8.512382   \n",
       "\n",
       "            ALAND      AWATER  ALAND_SQMI  AWATER_SQMI   INTPTLAT  \\\n",
       "USPS                                                                \n",
       "AK    120428818.0  13605012.0      46.498        5.253  59.708319   \n",
       "AL     91371430.0     86324.0      35.279        0.033  34.457495   \n",
       "AR    812912293.0   1721231.0     313.867        0.665  33.814492   \n",
       "AZ      3168111.0         0.0       1.223        0.000  32.143460   \n",
       "CA      1903988.0         0.0       0.735        0.000  34.026072   \n",
       "\n",
       "      INTPTLONG                                                                                                                               \n",
       "USPS                                                                                                                                          \n",
       "AK                                          -151.545304                                                                                       \n",
       "AL                                           -85.635214                                                                                       \n",
       "AR                                           -92.147621                                                                                       \n",
       "AZ                                          -110.918635                                                                                       \n",
       "CA                                          -117.736203                                                                                       "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This isn't a SQL-style 'GROUP BY'.\n",
    "df_joined.groupby('USPS').first().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6bd76a78d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the analog of\n",
    "# SELECT USPS, SUM(AMT_FHA), SUM(AMT_ALL), ... FROM df GROUP BY USPS;\n",
    "df_by_state = df_joined[['USPS', 'AMT_FHA', 'AMT_ALL', 'NUM_FHA', 'NUM_ALL']].groupby('USPS').sum()\n",
    "\n",
    "df_by_state['PCT_AMT_FHA'] = 100.0 * df_by_state['AMT_FHA']  / df_by_state['AMT_ALL']\n",
    "df_by_state['PCT_NUM_FHA'] = 100.0 * df_by_state['NUM_FHA']  / df_by_state['NUM_ALL']\n",
    "\n",
    "# This sure looks different than the census-tract level histogram!\n",
    "df_by_state['PCT_AMT_FHA'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NA handling\n",
    "\n",
    "\n",
    "When you read in a CSV file / SQL data base there are often \"NA\" (or \"null\", \"None\", etc.) values.  The CSV reader has a special field for specifying how this is denoted, and SQL has the built-in notion of NULL.  Pandas provides some tools for working with these -- they are generally similar too (and a little bit worse than) `R`\n",
    "\n",
    "- `isnull` / `notnull`: Testing for null-ness e.g., \n",
    ">       \n",
    "        df['column_name'].isnull()\n",
    "        \n",
    "   returns a Boolean series\n",
    "- `fillna`: Replacing null values by something else, e.g.,\n",
    ">         \n",
    "        df['column_name'].fillna(0)             # Fills constant value, here 0\n",
    "        df['column_name'].fillna(method='ffill')  # Fill forwards\n",
    "        df['column_name'].fillna(method='bfill', limit=5)  # Fill backwards, at most 5\n",
    "        \n",
    "    At least by default, this is *not in place* -- that is, it creates a new series and does not change the original one.\n",
    "\n",
    "- `interpolate`: Replacing null values by (linear, or quadratic, or...) interpolation.  There is support for indexing by times (not necessarily equally spaced), etc. in the documentation.  The most basic usage is\n",
    ">        \n",
    "        df['column_name'].interpolate()\n",
    "    \n",
    "    As above, this is not in place.\n",
    "\n",
    "\n",
    "For more details: http://pandas.pydata.org/pandas-docs/stable/missing_data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
